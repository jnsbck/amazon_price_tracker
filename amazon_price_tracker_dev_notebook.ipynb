{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # for plotting price data\n",
    "import pandas as pd\n",
    "from pandas.errors import EmptyDataError # error produced if empty csv if parsed\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests # fetches html content of a website, instead of urllib2 previously\n",
    "from urllib.request import HTTPError # for catching timeout for website response\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import URLError\n",
    "\n",
    "import time # for sleep function\n",
    "from datetime import datetime # for timestamp\n",
    "\n",
    "import os # for creation of directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracker\n",
    "- price_hist\n",
    "- tracked items\n",
    "    - deploy\n",
    "    - current_prices\n",
    "    - add and remove items\n",
    "    - fetch prices\n",
    "    - reset\n",
    "    - retrieve price hist and items from file\n",
    "    - log activity\n",
    "#### Components (sub-classes)\n",
    "- notify\n",
    "    - daily/weekly etc. (incl. plot?)\n",
    "    - notify if price hike or drop for a certain item\n",
    "    - notify if tracker goes down somehow\n",
    "- connectivity\n",
    "    - check connectivity\n",
    "- item\n",
    "    - price\n",
    "    - url\n",
    "    - ASIN\n",
    "    - nickname\n",
    "    - name\n",
    "- scraper\n",
    "    - find price\n",
    "    - find items left\n",
    "    - find prices of other vendors?\n",
    "- visualise\n",
    "    - different options to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonPriceTracker:\n",
    "    \n",
    "    def __init__(self, tracker_name=\"tracker\"):\n",
    "        self.items = {\"nicknames\": [], \"names\": [], \"asins\": [], \"urls\": []}\n",
    "        self.name = tracker_name\n",
    "        self.PATH = \"./\" + self.name + \"/\"\n",
    "        try:\n",
    "            os.mkdir(str(self.name))\n",
    "        except FileExistsError:\n",
    "            print(\"This tracker already exists. Using the existing one instead.\")\n",
    "        \n",
    "        self.price_history = {}\n",
    "        self.__retrieve_items()\n",
    "        \n",
    "        DateTime = [\"year\", \"month\", \"day\", \"hour\", \"minute\"]\n",
    "        self.price_history = pd.DataFrame(columns=DateTime+self.items[\"nicknames\"])\n",
    "        \n",
    "        self.__retrieve_price_hist()\n",
    "        self.latest_prices = self.price_history.tail(1)\n",
    "        \n",
    "    def __webpage2html(self, URL, parser=\"html.parser\"):\n",
    "        headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "        }\n",
    "        res = requests.get(URL, headers=headers)\n",
    "        res.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(res.text, parser)\n",
    "        return soup\n",
    "\n",
    "     \n",
    "    def add_item(self, URL, nickname):\n",
    "        if \"amazon\" not in URL:\n",
    "            print(\"This is not a valid amazon url.\")\n",
    "        else:\n",
    "            ASIN = URL.split(\"/\")[4]\n",
    "            URL = \"/\".join(URL.split(\"/\")[:5])\n",
    "            if ASIN not in self.items[\"asins\"]:\n",
    "                print(\"Adding item to list of tracked items.\")\n",
    "                try:\n",
    "                    soup = self.__webpage2html(URL)\n",
    "\n",
    "                    # extract name\n",
    "                    for element in soup.find_all(\"span\"):\n",
    "                        if \"productTitle\" in str(element):\n",
    "                            title_containing_str = str(element)\n",
    "                            break\n",
    "                    title_containing_str_start = title_containing_str.find(\">\")+1\n",
    "                    title_containing_str_end = title_containing_str.find(\"</\")\n",
    "                    title_raw = title_containing_str[title_containing_str_start:title_containing_str_end]\n",
    "                    title = title_raw.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "                    # save title and URL to txt\n",
    "                    f = open(self.PATH + \"tracked_items.txt\",\"a\", newline=\"\\n\")\n",
    "                    if title not in self.items[\"names\"]:\n",
    "                        f.write(nickname + \" : \" + title + \" : \" + URL + \" : \" + ASIN + \"\\n\")\n",
    "                    f.close()\n",
    "\n",
    "                    # save title and URL to dict\n",
    "                    self.items[\"names\"].append(title)\n",
    "                    self.items[\"urls\"].append(URL)\n",
    "                    self.items[\"nicknames\"].append(nickname)\n",
    "                    self.items[\"asins\"].append(ASIN)\n",
    "                    print(\"{} was succesfully added to list of tracked items.\".format(nickname))\n",
    "\n",
    "                except HTTPError:\n",
    "                    print(\"HTTP 503 Error, try to add item again later.\")\n",
    "            else:\n",
    "                print(\"This item is already being tracked.\")\n",
    "            \n",
    "            \n",
    "    def __retrieve_items(self):\n",
    "        # retrieve tracked items\n",
    "        try:\n",
    "            f = open(self.PATH + \"tracked_items.txt\", \"r\")\n",
    "            if f.read() == \"\":\n",
    "                print(\"No items are being tracked so far. \\\n",
    "                Please add an item to be tracked using .add_item().\")\n",
    "                f.close()\n",
    "            else:\n",
    "                f = open(self.PATH + \"tracked_items.txt\", \"r\")\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    nickname, title, url, asin = line.split(\" : \")\n",
    "                    if asin[:-1] not in self.items[\"asins\"]:\n",
    "                        self.items[\"names\"].append(title)\n",
    "                        self.items[\"urls\"].append(url)\n",
    "                        self.items[\"nicknames\"].append(nickname)\n",
    "                        self.items[\"asins\"].append(asin[:-1])\n",
    "            f.close()\n",
    "        except FileNotFoundError:\n",
    "            open(self.PATH + \"tracked_items.txt\", \"x\")\n",
    "    \n",
    "    \n",
    "    def __retrieve_price_hist(self):\n",
    "        try:\n",
    "            self.price_history = pd.read_csv(self.PATH + \"price_history.csv\")\n",
    "        except FileNotFoundError:\n",
    "            open(self.PATH + \"price_history.csv\", \"x\")\n",
    "        except EmptyDataError:\n",
    "            if len(self.items[\"names\"]) > 0:\n",
    "                print(\"The price history is empty so far. \\\n",
    "                Please fetch prices using .fetch_prices() first.\")\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        \n",
    "    def wipe_database(self):\n",
    "        # delete contents of files\n",
    "        items = open(self.PATH + \"tracked_items.txt\", \"w\")\n",
    "        items.write(\"\")\n",
    "        items.close()\n",
    "        \n",
    "        hist = open(self.PATH + \"price_history.csv\", \"w\")\n",
    "        hist.write(\"\")\n",
    "        hist.close()\n",
    "        \n",
    "        \n",
    "    def fetch_prices(self, URLs=None):  \n",
    "        # extract price\n",
    "        if URLs is None:\n",
    "            URLs = self.items[\"urls\"]\n",
    "        error_status = None\n",
    "        delay = 1 # delay between fetching items in s\n",
    "        DateTime = [\"year\", \"month\", \"day\", \"hour\", \"minute\"]\n",
    "        new_row = pd.DataFrame(columns=DateTime+self.items[\"nicknames\"])\n",
    "        if len(self.items[\"names\"]) > 0:\n",
    "            for n, URL in enumerate(URLs):\n",
    "                try:\n",
    "                    print(\"Fetching price for {}.\".format(self.items[\"nicknames\"][n]))\n",
    "                    soup = self.__webpage2html(URL, \"html.parser\")\n",
    "                    time.sleep(delay)\n",
    "                    item_name = self.items[\"nicknames\"][n]\n",
    "                    try:\n",
    "                        price_str = soup.select(\"#priceblock_ourprice\")[0].text.replace(\",\",\".\")\n",
    "                        price = float(price_str[:price_str.index(\".\")+3])\n",
    "                        new_row[item_name] = [price]\n",
    "                    except IndexError:\n",
    "                        print(\"The item or price is currently unavailable.\")\n",
    "                        new_row[item_name] = [np.NaN]\n",
    "                    \n",
    "                except HTTPError:\n",
    "                    item_name = self.items[\"nicknames\"][n]\n",
    "                    new_row[item_name] = [np.NaN]\n",
    "                    print(\"\\n A price for {} could not be fetched.\".format(item_name))\n",
    "                    error_status = True\n",
    "        \n",
    "            now = datetime.now()\n",
    "            datetime_vec = now.timetuple()[0:5]\n",
    "            new_row[DateTime] = datetime_vec\n",
    "            new_row.index = range(self.price_history.shape[0],self.price_history.shape[0]+1)\n",
    "            self.price_history = self.price_history.append(new_row, sort=False, ignore_index=True)\n",
    "            self.latest_prices = self.price_history.tail(1)\n",
    "\n",
    "            # save price history\n",
    "            self.price_history.to_csv(self.PATH + \"price_history.csv\", index_label=False, index=False)\n",
    "    \n",
    "        else:\n",
    "            print(\"There is no items to fetch a price for. Please add items using .add_item() first.\")\n",
    "    \n",
    "        return error_status\n",
    "                \n",
    "        \n",
    "    def remove_item(self):\n",
    "        print(\"The items currently being tracked are: \\n\")\n",
    "        for i in range(len(self.items[\"nicknames\"])):\n",
    "            print(\"[\" + str(i) + \"] --> \" + self.items[\"nicknames\"][i])\n",
    "        Input = input(\"\\n To remove an item from tracking enter the corresponding number.\\\n",
    "        \\n To cancel, press 'Enter'. \")\n",
    "        if Input.isdigit():\n",
    "            item2delete_idx = int(Input)\n",
    "            if item2delete_idx < len(self.items[\"nicknames\"]):\n",
    "                item_name = self.items[\"nicknames\"][item2delete_idx]\n",
    "\n",
    "                # remove from hist\n",
    "                self.price_history = self.price_history.drop(item_name, axis=1)\n",
    "                \n",
    "                # remove from tracked items\n",
    "                self.items[\"names\"].pop(item2delete_idx)\n",
    "                self.items[\"nicknames\"].pop(item2delete_idx)\n",
    "                self.items[\"urls\"].pop(item2delete_idx)\n",
    "                self.items[\"asins\"].pop(item2delete_idx)\n",
    "                \n",
    "                # remove from corresponding .txt and .csv\n",
    "                f_read = open(self.PATH + \"tracked_items.txt\", \"r\")\n",
    "                lines = f_read.readlines()\n",
    "                lines.pop(item2delete_idx)\n",
    "                f_write = open(self.PATH + \"tracked_items.txt\", \"w\")\n",
    "                f_write.write(\"\".join(lines))\n",
    "                f_read.close()\n",
    "                f_write.close()\n",
    "                \n",
    "                self.price_history.to_csv(self.PATH + \"price_history.csv\", index_label=False)\n",
    "                \n",
    "                print(\"Item was removed.\")\n",
    "            else:\n",
    "                print(\"The input does not correspond to an item.\")\n",
    "        elif Input == \"\":\n",
    "            print(\"The action has been canceled.\")\n",
    "        else:\n",
    "            print(\"The input is not valid.\")\n",
    "        \n",
    "\n",
    "    def plot_prices(self, timescale=\"day\"):\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        time_axis = self.price_history[timescale]\n",
    "        tracked_items = list(self.price_history.columns)[5:]\n",
    "        for item in tracked_items:\n",
    "            plt.plot(time_axis,self.price_history[item], \"-o\" , label=item)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.xlabel(timescale + \"s\")\n",
    "        plt.ylabel(\"Price in €\")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def current_prices(self):\n",
    "        self.fetch_prices()\n",
    "        current_price = self.latest_prices\n",
    "        return current_price\n",
    "    \n",
    "    def __internet_on(self):\n",
    "        try:\n",
    "            urlopen('http://216.58.192.142', timeout=1)\n",
    "            return True\n",
    "        except URLError as err: \n",
    "            return False\n",
    "\n",
    "        \n",
    "    def deploy(self):\n",
    "        while True:\n",
    "            _time = datetime.now().timetuple()[2:5]\n",
    "            today = _time[0]\n",
    "            hour = _time[1]\n",
    "            minute = _time[2]\n",
    "            try:\n",
    "                prev_year, prev_month, prev_day, *_ = np.loadtxt(self.PATH + \"price_history.csv\", skiprows=1, delimiter=\",\")[-1]\n",
    "            except TypeError:\n",
    "                prev_year, prev_month, prev_day, *_ = np.loadtxt(self.PATH + \"price_history.csv\", skiprows=1, delimiter=\",\")\n",
    "            except StopIteration:\n",
    "                prev_year, prev_month, prev_day = -1, -1, -1\n",
    "            print(\"Checking time...\")\n",
    "            if hour == 0 and (minute < 59 and minute > 0):\n",
    "                if prev_day != today:\n",
    "                    attempt = 1\n",
    "                    URLs = np.array(self.items[\"urls\"])\n",
    "                    while attempt < 10:\n",
    "                        try:\n",
    "                            print(\"Attempt {} to fetch prices.\".format(attempt))\n",
    "                            status = self.fetch_prices(URLs)\n",
    "                            if status == None:\n",
    "                                print(\"Fetching was a success!\")\n",
    "                                print(\"...waiting for next fetch.\")\n",
    "                                break\n",
    "                            else:\n",
    "                                latest_prices = self.price_history.iloc[-1,5:]\n",
    "                                fails = np.array(latest_prices.isna())\n",
    "                                URLs = URLs[fails]\n",
    "                                attempt += 1\n",
    "                                nicknames_of_fails = np.array(self.items[\"nicknames\"])[fails]\n",
    "                                print(\"Encountered an error while fetching prices for {}. Trying again in 10 min.\".format(list(nicknames_of_fails)))\n",
    "                                time.sleep(10*60)\n",
    "                        except HTTPError:\n",
    "                            print(\"HTTP 503 Error, trying again in 10 minutes.\")\n",
    "                            attempt += 1\n",
    "                            time.sleep(10*60)\n",
    "                else:\n",
    "                    print(\"Item prices have already been updated today.\")\n",
    "            time.sleep(59*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def notify(self, email):\n",
    "#             send email with price plot\n",
    "\n",
    "#     def request_update(self.):\n",
    "#         update prices and send email with current prices and history of them at the request\n",
    "    \n",
    "# add functionality to see how many items are left in stock if possible!!!\n",
    "# add functionality to recieve an email every day with plot of price developement and if anything as changed\n",
    "# add functionality to compare prices to other vendors\n",
    "# e.g. open with urllib https://www.amazon.de/gp/offer-listing/ (ASIN --> B07SXMZLPK) /ref=dp_olp_new_mbc?ie=UTF8&condition=new\n",
    "# and scrape webpage for all the prices in soup.select(\"#olpOfferList\")[0].div.div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
