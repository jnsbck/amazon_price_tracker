{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # for plotting price data\n",
    "import pandas as pd\n",
    "from pandas.errors import EmptyDataError # error produced if empty csv if parsed\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from urllib.request import HTTPError # for catching timeout for website response\n",
    "\n",
    "import time # for sleep function\n",
    "from datetime import datetime # for timestamp\n",
    "\n",
    "import os # for creation of directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonPriceTracker:\n",
    "    \n",
    "    def __init__(self, tracker_name=\"tracker\"):\n",
    "        self.items = {\"nicknames\": [], \"names\": [], \"asins\": [], \"urls\": []}\n",
    "        self.name = tracker_name\n",
    "        self.PATH = \"./\" + self.name + \"/\"\n",
    "        try:\n",
    "            os.mkdir(str(self.name))\n",
    "        except FileExistsError:\n",
    "            print(\"This tracker already exists. Using the existing one instead.\")\n",
    "        \n",
    "        self.price_history = {}\n",
    "        self.__retrieve_items()\n",
    "        \n",
    "        DateTime = [\"year\", \"month\", \"day\", \"hour\", \"minute\"]\n",
    "        self.price_history = pd.DataFrame(columns=DateTime+self.items[\"nicknames\"])\n",
    "        \n",
    "        self.__retrieve_price_hist()\n",
    "        self.latest_prices = self.price_history.tail(1)\n",
    "        \n",
    "    def __webpage2html(self, URL, parser=\"html.parser\"):\n",
    "        hdr = { 'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)' }\n",
    "        req = urllib.request.Request(URL, headers=hdr)\n",
    "        with urllib.request.urlopen(req) as f:\n",
    "            html_doc = f.read()\n",
    "        return BeautifulSoup(html_doc, parser)\n",
    "\n",
    "        \n",
    "    def add_item(self, URL, nickname):\n",
    "        if \"amazon\" not in URL:\n",
    "            print(\"This is not a valid amazon url.\")\n",
    "        else:\n",
    "            ASIN = URL.split(\"/\")[4]\n",
    "            URL = \"/\".join(URL.split(\"/\")[:5])\n",
    "            if ASIN not in self.items[\"asins\"]:\n",
    "                print(\"Adding item to list of tracked items.\")\n",
    "                try:\n",
    "                    soup = self.__webpage2html(URL)\n",
    "\n",
    "                    # extract name\n",
    "                    for element in soup.find_all(\"span\"):\n",
    "                        if \"productTitle\" in str(element):\n",
    "                            title_containing_str = str(element)\n",
    "                            break\n",
    "                    title_containing_str_start = title_containing_str.find(\">\")+1\n",
    "                    title_containing_str_end = title_containing_str.find(\"</\")\n",
    "                    title_raw = title_containing_str[title_containing_str_start:title_containing_str_end]\n",
    "                    title = title_raw.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "                    # save title and URL to txt\n",
    "                    f = open(self.PATH + \"tracked_items.txt\",\"a\", newline=\"\\n\")\n",
    "                    if title not in self.items[\"names\"]:\n",
    "                        f.write(nickname + \" : \" + title + \" : \" + URL + \" : \" + ASIN + \"\\n\")\n",
    "                    f.close()\n",
    "\n",
    "                    # save title and URL to dict\n",
    "                    self.items[\"names\"].append(title)\n",
    "                    self.items[\"urls\"].append(URL)\n",
    "                    self.items[\"nicknames\"].append(nickname)\n",
    "                    self.items[\"asins\"].append(ASIN)\n",
    "                    print(\"{} was succesfully added to list of tracked items.\".format(nickname))\n",
    "\n",
    "                except HTTPError:\n",
    "                    print(\"HTTP 503 Error, try to add item again later.\")\n",
    "            else:\n",
    "                print(\"This item is already being tracked.\")\n",
    "            \n",
    "            \n",
    "    def __retrieve_items(self):\n",
    "        # retrieve tracked items\n",
    "        try:\n",
    "            f = open(self.PATH + \"tracked_items.txt\", \"r\")\n",
    "            if f.read() == \"\":\n",
    "                print(\"No items are being tracked so far. \\\n",
    "                Please add an item to be tracked using .add_item().\")\n",
    "                f.close()\n",
    "            else:\n",
    "                f = open(self.PATH + \"tracked_items.txt\", \"r\")\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    nickname, title, url, asin = line.split(\" : \")\n",
    "                    if asin[:-1] not in self.items[\"asins\"]:\n",
    "                        self.items[\"names\"].append(title)\n",
    "                        self.items[\"urls\"].append(url)\n",
    "                        self.items[\"nicknames\"].append(nickname)\n",
    "                        self.items[\"asins\"].append(asin[:-1])\n",
    "            f.close()\n",
    "        except FileNotFoundError:\n",
    "            open(self.PATH + \"tracked_items.txt\", \"x\")\n",
    "    \n",
    "    \n",
    "    def __retrieve_price_hist(self):\n",
    "        try:\n",
    "            self.price_history = pd.read_csv(self.PATH + \"price_history.csv\")\n",
    "        except FileNotFoundError:\n",
    "            open(self.PATH + \"price_history.csv\", \"x\")\n",
    "        except EmptyDataError:\n",
    "            if len(self.items[\"names\"]) > 0:\n",
    "                print(\"The price history is empty so far. \\\n",
    "                Please fetch prices using .fetch_prices() first.\")\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        \n",
    "    def wipe_database(self):\n",
    "        # delete contents of files\n",
    "        items = open(self.PATH + \"tracked_items.txt\", \"w\")\n",
    "        items.write(\"\")\n",
    "        items.close()\n",
    "        \n",
    "        hist = open(self.PATH + \"price_history.csv\", \"w\")\n",
    "        hist.write(\"\")\n",
    "        hist.close()\n",
    "        \n",
    "        \n",
    "    def fetch_prices(self, URLs=None):  \n",
    "        # extract price\n",
    "        if URLs is None:\n",
    "            URLs = self.items[\"urls\"]\n",
    "        error_status = False\n",
    "        delay = 1 # delay between fetching items in s\n",
    "        DateTime = [\"year\", \"month\", \"day\", \"hour\", \"minute\"]\n",
    "        new_row = pd.DataFrame(columns=DateTime+self.items[\"nicknames\"])\n",
    "        if len(self.items[\"names\"]) > 0:\n",
    "            for n, URL in enumerate(URLs):\n",
    "                try:\n",
    "                    print(\"Fetching price for {}.\".format(self.items[\"nicknames\"][n]))\n",
    "                    soup = self.__webpage2html(URL, \"lxml\")\n",
    "                    time.sleep(delay)\n",
    "\n",
    "                    price_str = soup.select(\"#priceblock_ourprice\")[0].text.replace(\",\",\".\")\n",
    "                    price = float(price_str[:price_str.index(\".\")+3])\n",
    "                    item_name = self.items[\"nicknames\"][n]\n",
    "                    new_row[item_name] = [price]\n",
    "                    \n",
    "                except HTTPError:\n",
    "                    item_name = self.items[\"nicknames\"][n]\n",
    "                    new_row[item_name] = [np.NaN]\n",
    "                    print(\"\\n A price for {} could not be fetched.\".format(item_name))\n",
    "                    error_status = True\n",
    "        else:\n",
    "            print(\"There is no items to fetch a price for. Please add items using .add_item() first.\")\n",
    "\n",
    "        now = datetime.now()\n",
    "        datetime_vec = now.timetuple()[0:5]\n",
    "        new_row[DateTime] = datetime_vec\n",
    "        new_row.index = range(self.price_history.shape[0],self.price_history.shape[0]+1)\n",
    "        self.price_history = self.price_history.append(new_row, sort=False, ignore_index=True)\n",
    "        self.latest_prices = self.price_history.tail(1)\n",
    "\n",
    "        # save price history\n",
    "        self.price_history.to_csv(self.PATH + \"price_history.csv\", index_label=False, index=False)\n",
    "        return error_status\n",
    "                \n",
    "        \n",
    "    def remove_item(self):\n",
    "        print(\"The items currently being tracked are: \\n\")\n",
    "        for i in range(len(self.items[\"nicknames\"])):\n",
    "            print(\"[\" + str(i) + \"] --> \" + self.items[\"nicknames\"][i])\n",
    "        Input = input(\"\\n To remove an item from tracking enter the corresponding number.\\\n",
    "        \\n To cancel, press 'Enter'. \")\n",
    "        if Input.isdigit():\n",
    "            item2delete_idx = int(Input)\n",
    "            if item2delete_idx < len(self.items[\"nicknames\"]):\n",
    "                item_name = self.items[\"nicknames\"][item2delete_idx]\n",
    "\n",
    "                # remove from hist\n",
    "                self.price_history = self.price_history.drop(item_name, axis=1)\n",
    "                \n",
    "                # remove from tracked items\n",
    "                self.items[\"names\"].pop(item2delete_idx)\n",
    "                self.items[\"nicknames\"].pop(item2delete_idx)\n",
    "                self.items[\"urls\"].pop(item2delete_idx)\n",
    "                self.items[\"asins\"].pop(item2delete_idx)\n",
    "                \n",
    "                # remove from corresponding .txt and .csv\n",
    "                f_read = open(self.PATH + \"tracked_items.txt\", \"r\")\n",
    "                lines = f_read.readlines()\n",
    "                lines.pop(item2delete_idx)\n",
    "                f_write = open(self.PATH + \"tracked_items.txt\", \"w\")\n",
    "                f_write.write(\"\".join(lines))\n",
    "                f_read.close()\n",
    "                f_write.close()\n",
    "                \n",
    "                self.price_history.to_csv(self.PATH + \"price_history.csv\", index_label=False)\n",
    "                \n",
    "                print(\"Item was removed.\")\n",
    "            else:\n",
    "                print(\"The input does not correspond to an item.\")\n",
    "        elif Input == \"\":\n",
    "            print(\"The action has been canceled.\")\n",
    "        else:\n",
    "            print(\"The input is not valid.\")\n",
    "        \n",
    "\n",
    "    def plot_prices(self, timescale=\"day\"):\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        time_axis = self.price_history[timescale]\n",
    "        tracked_items = list(tracker.price_history.columns)[5:]\n",
    "        for item in tracked_items:\n",
    "            plt.plot(time_axis,tracker.price_history[item], \"-o\" , label=item)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.xlabel(timescale + \"s\")\n",
    "        plt.ylabel(\"Price in €\")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def current_prices(self):\n",
    "        self.fetch_prices()\n",
    "        current_price = self.latest_prices\n",
    "        return current_price\n",
    "\n",
    "        \n",
    "    def deploy(self):\n",
    "        while True:\n",
    "            _time = datetime.now().timetuple()[2:5]\n",
    "            today = _time[0]\n",
    "            hour = _time[1]\n",
    "            minute = _time[2]\n",
    "            try:\n",
    "                prev_year, prev_month, prev_day, *_ = np.loadtxt(self.PATH + \"price_history.csv\", skiprows=1, delimiter=\",\")[-1]\n",
    "            except TypeError:\n",
    "                prev_year, prev_month, prev_day, *_ = np.loadtxt(self.PATH + \"price_history.csv\", skiprows=1, delimiter=\",\")\n",
    "            except StopIteration:\n",
    "                prev_year, prev_month, prev_day = -1, -1, -1\n",
    "            print(\"Checking time...\")\n",
    "            if hour == 0 and (minute < 59 and minute > 0):\n",
    "                if prev_day != today:\n",
    "                    attempt = 1\n",
    "                    URLs = np.array(self.items[\"urls\"])\n",
    "                    while attempt < 10:\n",
    "                        try:\n",
    "                            print(\"Attempt {} to fetch prices.\".format(attempt))\n",
    "                            status = self.fetch_prices(URLs)\n",
    "                            if status == 0:\n",
    "                                print(\"Fetching was a success!\")\n",
    "                                print(\"...waiting for next fetch.\")\n",
    "                                break\n",
    "                            else:\n",
    "                                latest_prices = self.price_history.iloc[-1,5:]\n",
    "                                fails = np.array(latest_prices.isna())\n",
    "                                URLs = URLs[fails]\n",
    "                                attempt += 1\n",
    "                                nicknames_of_fails = np.array(self.items[\"nicknames\"])[fails]\n",
    "                                print(\"Encountered an error while fetching prices for {}. Trying again in 10 min.\".format(list(nicknames_of_fails)))\n",
    "                                time.sleep(10*60)\n",
    "                        except HTTPError:\n",
    "                            print(\"HTTP 503 Error, trying again in 10 minutes.\")\n",
    "                            attempt += 1\n",
    "                            time.sleep(10*60)\n",
    "                else:\n",
    "                    print(\"Item prices have already been updated today.\")\n",
    "            time.sleep(59*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def notify(self, email):\n",
    "#             send email with price plot\n",
    "\n",
    "#     def request_update(self.):\n",
    "#         update prices and send email with current prices and history of them at the request\n",
    "  \n",
    "# def check_connectivity(self):\n",
    "    \n",
    "# add functionality to see how many items are left in stock if possible!!!\n",
    "# add functionality to recieve an email every day with plot of price developement and if anything as changed\n",
    "# add functionality to compare prices to other vendors\n",
    "# e.g. open with urllib https://www.amazon.de/gp/offer-listing/ (ASIN --> B07SXMZLPK) /ref=dp_olp_new_mbc?ie=UTF8&condition=new\n",
    "# and scrape webpage for all the prices in soup.select(\"#olpOfferList\")[0].div.div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tracker already exists. Using the existing one instead.\n"
     ]
    }
   ],
   "source": [
    "tracker = AmazonPriceTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This item is already being tracked.\n",
      "This item is already being tracked.\n",
      "This item is already being tracked.\n"
     ]
    }
   ],
   "source": [
    "URL1 = \"https://www.amazon.de/dp/B07H289S79/ref=sr_1_1_sspa?crid=10NNT7QDBOWO4&keywords=4+TB+Seagate&qid=1576506626&sprefix=seagate+%2Caps%2C182&sr=8-1-spons&psc=1&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUEzMFZLNUFTSk5VQ0xFJmVuY3J5cHRlZElkPUEwNTEyOTI2M01OWldDVDI4SkYxMCZlbmNyeXB0ZWRBZElkPUEwNDkxOTQ0MVM0UVZGR0hKWkZUUSZ3aWRnZXROYW1lPXNwX2F0ZiZhY3Rpb249Y2xpY2tSZWRpcmVjdCZkb05vdExvZ0NsaWNrPXRydWU=\"\n",
    "URL2 = \"https://www.amazon.de/dp/B07SXMZLPK/ref=sr_1_4?keywords=ryzen+3700x&qid=1577491082&sr=8-4\"\n",
    "URL3 = \"https://www.amazon.de/dp/B07MFBLN7K/ref=sr_1_5?keywords=samsung+500gb+ssd&qid=1577491138&sr=8-5\"\n",
    "tracker.add_item(URL1, \"Seagate 4TB HDD\")\n",
    "tracker.add_item(URL2, \"Ryzen 3700x\")\n",
    "tracker.add_item(URL3, \"500 GB Samsung SSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking time...\n",
      "Item prices have already been updated today.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-712-b41001b32d36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-709-17c9a260c218>\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Item prices have already been updated today.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m59\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tracker.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
